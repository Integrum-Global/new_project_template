# Docker Compose for MCP + Kailash Production Deployment
#
# This configuration demonstrates a production-ready deployment of MCP servers
# using Kailash SDK with service discovery, authentication, and monitoring.

version: '3.8'

services:
  # Main Kailash MCP Server
  kailash-mcp-server:
    build:
      context: .
      dockerfile: Dockerfile.kailash-server
    ports:
      - "8080:8080"
    environment:
      - MCP_SERVER_NAME=kailash-production-server
      - MCP_PORT=8080
      - MCP_AUTH_ENABLED=true
      - MCP_METRICS_ENABLED=true
      - REDIS_URL=redis://redis:6379
      - POSTGRES_URL=postgresql://postgres:password@postgres:5432/kailash_mcp
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - redis
      - postgres
      - ollama
    networks:
      - mcp-network
    volumes:
      - ./config:/app/config
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Specialized AI Analysis Server
  ai-analyst-server:
    build:
      context: .
      dockerfile: Dockerfile.ai-analyst
    ports:
      - "8081:8081"
    environment:
      - MCP_SERVER_NAME=ai-analyst-server
      - MCP_PORT=8081
      - MCP_CAPABILITIES=data_analysis,pattern_recognition,insight_generation
      - OLLAMA_URL=http://ollama:11434
      - REGISTRY_URL=http://service-registry:8090
    depends_on:
      - ollama
      - service-registry
    networks:
      - mcp-network
    restart: unless-stopped

  # Data Processing Server
  data-processor-server:
    build:
      context: .
      dockerfile: Dockerfile.data-processor
    ports:
      - "8082:8082"
    environment:
      - MCP_SERVER_NAME=data-processor-server
      - MCP_PORT=8082
      - MCP_CAPABILITIES=data_processing,transformation,enrichment
      - REDIS_URL=redis://redis:6379
      - POSTGRES_URL=postgresql://postgres:password@postgres:5432/kailash_mcp
    depends_on:
      - redis
      - postgres
    networks:
      - mcp-network
    restart: unless-stopped

  # Service Registry and Discovery
  service-registry:
    image: consul:1.15
    ports:
      - "8090:8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
    networks:
      - mcp-network
    volumes:
      - consul-data:/consul/data
    restart: unless-stopped

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - mcp-network
    volumes:
      - redis-data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes

  # PostgreSQL for persistent data
  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=kailash_mcp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    networks:
      - mcp-network
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    restart: unless-stopped

  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    networks:
      - mcp-network
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    networks:
      - mcp-network
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - kailash-mcp-server
      - ai-analyst-server
      - data-processor-server
    restart: unless-stopped

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    networks:
      - mcp-network
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    restart: unless-stopped

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    networks:
      - mcp-network
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    restart: unless-stopped

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - mcp-network
    restart: unless-stopped

  # MCP Client Demo Application
  mcp-client-demo:
    build:
      context: .
      dockerfile: Dockerfile.client-demo
    ports:
      - "8888:8888"
    environment:
      - MCP_SERVER_URLS=http://kailash-mcp-server:8080,http://ai-analyst-server:8081,http://data-processor-server:8082
      - SERVICE_REGISTRY_URL=http://service-registry:8500
    depends_on:
      - kailash-mcp-server
      - ai-analyst-server
      - data-processor-server
      - service-registry
    networks:
      - mcp-network
    restart: unless-stopped

networks:
  mcp-network:
    driver: bridge

volumes:
  redis-data:
  postgres-data:
  ollama-data:
  consul-data:
  prometheus-data:
  grafana-data:
