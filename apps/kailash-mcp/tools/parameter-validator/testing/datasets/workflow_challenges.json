{
  "metadata": {
    "version": "1.0",
    "created_for": "MCP Parameter Validation Tool A/B Testing",
    "bias_free": true,
    "total_challenges": 80,
    "levels_distribution": {
      "Level 1": 20,
      "Level 2": 20,
      "Level 3": 20,
      "Level 4": 20
    }
  },
  "challenges": [
    {
      "challenge_id": "WF101",
      "level": 1,
      "pattern": "linear",
      "domain": "compliance_checking",
      "title": "Audit Trail Generator",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF102",
      "level": 1,
      "pattern": "linear",
      "domain": "api_integration",
      "title": "Service Integration Hub",
      "description": "Develop an integration workflow that coordinates multiple external APIs, handles authentication, and manages response data. Design for simple integration scenarios.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF103",
      "level": 1,
      "pattern": "linear",
      "domain": "inventory_management",
      "title": "Stock Level Monitor",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF104",
      "level": 1,
      "pattern": "linear",
      "domain": "research_automation",
      "title": "Literature Review System",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF105",
      "level": 1,
      "pattern": "linear",
      "domain": "research_automation",
      "title": "Data Collection Pipeline",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF106",
      "level": 1,
      "pattern": "linear",
      "domain": "compliance_checking",
      "title": "Audit Trail Generator",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF107",
      "level": 1,
      "pattern": "linear",
      "domain": "financial_analysis",
      "title": "Risk Assessment System",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF108",
      "level": 1,
      "pattern": "linear",
      "domain": "social_media",
      "title": "Social Media Monitor",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF109",
      "level": 1,
      "pattern": "linear",
      "domain": "data_processing",
      "title": "ETL Workflow",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle simple data volumes and ensure quality standards.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF110",
      "level": 1,
      "pattern": "linear",
      "domain": "compliance_checking",
      "title": "Regulatory Monitor",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF111",
      "level": 1,
      "pattern": "linear",
      "domain": "financial_analysis",
      "title": "Transaction Processor",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF112",
      "level": 1,
      "pattern": "linear",
      "domain": "content_analysis",
      "title": "Text Analysis Pipeline",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement simple analysis techniques.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF113",
      "level": 1,
      "pattern": "linear",
      "domain": "social_media",
      "title": "Content Scheduler",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF114",
      "level": 1,
      "pattern": "linear",
      "domain": "content_analysis",
      "title": "Document Classifier",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement simple analysis techniques.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF115",
      "level": 1,
      "pattern": "linear",
      "domain": "monitoring_system",
      "title": "Alert Processing System",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement simple monitoring capabilities.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF116",
      "level": 1,
      "pattern": "linear",
      "domain": "data_processing",
      "title": "Data Validation Pipeline",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle simple data volumes and ensure quality standards.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF117",
      "level": 1,
      "pattern": "linear",
      "domain": "api_integration",
      "title": "Service Integration Hub",
      "description": "Develop an integration workflow that coordinates multiple external APIs, handles authentication, and manages response data. Design for simple integration scenarios.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF118",
      "level": 1,
      "pattern": "linear",
      "domain": "customer_service",
      "title": "Support Ticket Router",
      "description": "Create a simple workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF119",
      "level": 1,
      "pattern": "linear",
      "domain": "data_processing",
      "title": "ETL Workflow",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle simple data volumes and ensure quality standards.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF120",
      "level": 1,
      "pattern": "linear",
      "domain": "monitoring_system",
      "title": "Alert Processing System",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement simple monitoring capabilities.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 1,
        "expected_duration_minutes": 15
      }
    },
    {
      "challenge_id": "WF201",
      "level": 2,
      "pattern": "linear",
      "domain": "api_integration",
      "title": "Multi-API Orchestrator",
      "description": "Develop an integration workflow that coordinates multiple external APIs, handles authentication, and manages response data. Design for moderate integration scenarios.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF202",
      "level": 2,
      "pattern": "parallel",
      "domain": "compliance_checking",
      "title": "Compliance Validator with Parallel Processing",
      "description": "Create a moderate workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF203",
      "level": 2,
      "pattern": "linear",
      "domain": "financial_analysis",
      "title": "Portfolio Analyzer",
      "description": "Create a moderate workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF204",
      "level": 2,
      "pattern": "linear",
      "domain": "data_pipeline",
      "title": "Real-time Data Stream",
      "description": "Design a data pipeline that ingests, processes, and stores information from multiple sources. Handle moderate data transformation requirements.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF205",
      "level": 2,
      "pattern": "parallel",
      "domain": "content_analysis",
      "title": "Document Classifier with Parallel Processing",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement moderate analysis techniques. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF206",
      "level": 2,
      "pattern": "parallel",
      "domain": "financial_analysis",
      "title": "Transaction Processor with Parallel Processing",
      "description": "Create a moderate workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF207",
      "level": 2,
      "pattern": "parallel",
      "domain": "monitoring_system",
      "title": "Performance Tracker with Parallel Processing",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement moderate monitoring capabilities. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF208",
      "level": 2,
      "pattern": "linear",
      "domain": "document_workflow",
      "title": "Report Generator",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support moderate document types.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF209",
      "level": 2,
      "pattern": "linear",
      "domain": "inventory_management",
      "title": "Stock Level Monitor",
      "description": "Create a moderate workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF210",
      "level": 2,
      "pattern": "parallel",
      "domain": "content_analysis",
      "title": "Content Moderation System with Parallel Processing",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement moderate analysis techniques. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF211",
      "level": 2,
      "pattern": "parallel",
      "domain": "document_workflow",
      "title": "Document Processing Chain with Parallel Processing",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support moderate document types. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF212",
      "level": 2,
      "pattern": "linear",
      "domain": "research_automation",
      "title": "Literature Review System",
      "description": "Create a moderate workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF213",
      "level": 2,
      "pattern": "parallel",
      "domain": "data_pipeline",
      "title": "Data Transformation with Parallel Processing",
      "description": "Design a data pipeline that ingests, processes, and stores information from multiple sources. Handle moderate data transformation requirements. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF214",
      "level": 2,
      "pattern": "linear",
      "domain": "content_analysis",
      "title": "Document Classifier",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement moderate analysis techniques.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF215",
      "level": 2,
      "pattern": "linear",
      "domain": "financial_analysis",
      "title": "Portfolio Analyzer",
      "description": "Create a moderate workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF216",
      "level": 2,
      "pattern": "parallel",
      "domain": "data_processing",
      "title": "Data Validation Pipeline with Parallel Processing",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle moderate data volumes and ensure quality standards. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF217",
      "level": 2,
      "pattern": "parallel",
      "domain": "financial_analysis",
      "title": "Portfolio Analyzer with Parallel Processing",
      "description": "Create a moderate workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF218",
      "level": 2,
      "pattern": "linear",
      "domain": "research_automation",
      "title": "Literature Review System",
      "description": "Create a moderate workflow system for automated processing and analysis.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF219",
      "level": 2,
      "pattern": "linear",
      "domain": "content_analysis",
      "title": "Content Moderation System",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement moderate analysis techniques.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        2,
        4
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF220",
      "level": 2,
      "pattern": "parallel",
      "domain": "compliance_checking",
      "title": "Audit Trail Generator with Parallel Processing",
      "description": "Create a moderate workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 8 nodes in the workflow",
        "Use only standard Kailash SDK nodes"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 2,
        "expected_duration_minutes": 20
      }
    },
    {
      "challenge_id": "WF301",
      "level": 3,
      "pattern": "parallel",
      "domain": "research_automation",
      "title": "Data Collection Pipeline with Parallel Processing",
      "description": "Create a complex workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF302",
      "level": 3,
      "pattern": "parallel",
      "domain": "social_media",
      "title": "Content Scheduler with Parallel Processing",
      "description": "Create a complex workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF303",
      "level": 3,
      "pattern": "parallel",
      "domain": "compliance_checking",
      "title": "Audit Trail Generator with Parallel Processing",
      "description": "Create a complex workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF304",
      "level": 3,
      "pattern": "parallel",
      "domain": "customer_service",
      "title": "Customer Feedback Analyzer with Parallel Processing",
      "description": "Create a complex workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF305",
      "level": 3,
      "pattern": "cyclic",
      "domain": "customer_service",
      "title": "Response Automation with Feedback Loop",
      "description": "Create a complex workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF306",
      "level": 3,
      "pattern": "cyclic",
      "domain": "inventory_management",
      "title": "Supplier Communication with Feedback Loop",
      "description": "Create a complex workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF307",
      "level": 3,
      "pattern": "parallel",
      "domain": "document_workflow",
      "title": "PDF Analysis Pipeline with Parallel Processing",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support complex document types. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF308",
      "level": 3,
      "pattern": "cyclic",
      "domain": "inventory_management",
      "title": "Stock Level Monitor with Feedback Loop",
      "description": "Create a complex workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF309",
      "level": 3,
      "pattern": "parallel",
      "domain": "data_processing",
      "title": "ETL Workflow with Parallel Processing",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle complex data volumes and ensure quality standards. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF310",
      "level": 3,
      "pattern": "cyclic",
      "domain": "financial_analysis",
      "title": "Transaction Processor with Feedback Loop",
      "description": "Create a complex workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF311",
      "level": 3,
      "pattern": "parallel",
      "domain": "document_workflow",
      "title": "Report Generator with Parallel Processing",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support complex document types. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF312",
      "level": 3,
      "pattern": "parallel",
      "domain": "compliance_checking",
      "title": "Compliance Validator with Parallel Processing",
      "description": "Create a complex workflow system for automated processing and analysis. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF313",
      "level": 3,
      "pattern": "cyclic",
      "domain": "document_workflow",
      "title": "PDF Analysis Pipeline with Feedback Loop",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support complex document types. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF314",
      "level": 3,
      "pattern": "cyclic",
      "domain": "social_media",
      "title": "Social Media Monitor with Feedback Loop",
      "description": "Create a complex workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF315",
      "level": 3,
      "pattern": "parallel",
      "domain": "content_analysis",
      "title": "Text Analysis Pipeline with Parallel Processing",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement complex analysis techniques. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF316",
      "level": 3,
      "pattern": "parallel",
      "domain": "monitoring_system",
      "title": "System Health Monitor with Parallel Processing",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement complex monitoring capabilities. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF317",
      "level": 3,
      "pattern": "cyclic",
      "domain": "document_workflow",
      "title": "PDF Analysis Pipeline with Feedback Loop",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support complex document types. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF318",
      "level": 3,
      "pattern": "parallel",
      "domain": "api_integration",
      "title": "Service Integration Hub with Parallel Processing",
      "description": "Develop an integration workflow that coordinates multiple external APIs, handles authentication, and manages response data. Design for complex integration scenarios. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF319",
      "level": 3,
      "pattern": "parallel",
      "domain": "document_workflow",
      "title": "Document Processing Chain with Parallel Processing",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support complex document types. Optimize for concurrent processing of multiple data streams.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        4,
        8
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF320",
      "level": 3,
      "pattern": "cyclic",
      "domain": "content_analysis",
      "title": "Content Moderation System with Feedback Loop",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement complex analysis techniques. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 12 nodes in the workflow",
        "Include at least one cycle or parallel branch"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 3,
        "expected_duration_minutes": 25
      }
    },
    {
      "challenge_id": "WF401",
      "level": 4,
      "pattern": "cyclic",
      "domain": "compliance_checking",
      "title": "Regulatory Monitor with Feedback Loop",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF402",
      "level": 4,
      "pattern": "cyclic",
      "domain": "monitoring_system",
      "title": "Performance Tracker with Feedback Loop",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement enterprise-grade monitoring capabilities. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF403",
      "level": 4,
      "pattern": "hybrid",
      "domain": "monitoring_system",
      "title": "Alert Processing System - Advanced Integration",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement enterprise-grade monitoring capabilities. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF404",
      "level": 4,
      "pattern": "hybrid",
      "domain": "social_media",
      "title": "Content Scheduler - Advanced Integration",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF405",
      "level": 4,
      "pattern": "cyclic",
      "domain": "compliance_checking",
      "title": "Compliance Validator with Feedback Loop",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF406",
      "level": 4,
      "pattern": "hybrid",
      "domain": "content_analysis",
      "title": "Document Classifier - Advanced Integration",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement enterprise-grade analysis techniques. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF407",
      "level": 4,
      "pattern": "hybrid",
      "domain": "api_integration",
      "title": "Service Integration Hub - Advanced Integration",
      "description": "Develop an integration workflow that coordinates multiple external APIs, handles authentication, and manages response data. Design for enterprise-grade integration scenarios. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF408",
      "level": 4,
      "pattern": "hybrid",
      "domain": "inventory_management",
      "title": "Reorder Point Calculator - Advanced Integration",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF409",
      "level": 4,
      "pattern": "cyclic",
      "domain": "social_media",
      "title": "Social Media Monitor with Feedback Loop",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF410",
      "level": 4,
      "pattern": "hybrid",
      "domain": "social_media",
      "title": "Social Media Monitor - Advanced Integration",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF411",
      "level": 4,
      "pattern": "cyclic",
      "domain": "customer_service",
      "title": "Response Automation with Feedback Loop",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF412",
      "level": 4,
      "pattern": "hybrid",
      "domain": "monitoring_system",
      "title": "System Health Monitor - Advanced Integration",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement enterprise-grade monitoring capabilities. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "deprecated_patterns",
          "description": "Using cycle=True instead of CycleBuilder API",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF413",
      "level": 4,
      "pattern": "cyclic",
      "domain": "document_workflow",
      "title": "Document Processing Chain with Feedback Loop",
      "description": "Build a document processing system that handles file ingestion, content extraction, and structured output generation. Support enterprise-grade document types. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF414",
      "level": 4,
      "pattern": "hybrid",
      "domain": "data_processing",
      "title": "ETL Workflow - Advanced Integration",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle enterprise-grade data volumes and ensure quality standards. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF415",
      "level": 4,
      "pattern": "cyclic",
      "domain": "data_processing",
      "title": "Data Quality Monitor with Feedback Loop",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle enterprise-grade data volumes and ensure quality standards. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF416",
      "level": 4,
      "pattern": "cyclic",
      "domain": "data_processing",
      "title": "Data Quality Monitor with Feedback Loop",
      "description": "Build a workflow that processes incoming data through validation, transformation, and output stages. The system should handle enterprise-grade data volumes and ensure quality standards. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF417",
      "level": 4,
      "pattern": "hybrid",
      "domain": "monitoring_system",
      "title": "System Health Monitor - Advanced Integration",
      "description": "Create a monitoring workflow that collects system metrics, analyzes performance data, and triggers alerts when needed. Implement enterprise-grade monitoring capabilities. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "unused_imports",
          "description": "Imported modules not actually used",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF418",
      "level": 4,
      "pattern": "cyclic",
      "domain": "compliance_checking",
      "title": "Compliance Validator with Feedback Loop",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "incorrect_parameter_types",
          "description": "Parameter values don't match expected types",
          "detection_difficulty": "medium"
        },
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "missing_parameters",
          "description": "Required node parameters not provided",
          "detection_difficulty": "medium"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF419",
      "level": 4,
      "pattern": "hybrid",
      "domain": "customer_service",
      "title": "Support Ticket Router - Advanced Integration",
      "description": "Create a enterprise-grade workflow system for automated processing and analysis. Combine multiple processing patterns for maximum efficiency.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "relative_imports",
          "description": "Using relative instead of absolute imports",
          "detection_difficulty": "medium"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        },
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        }
      ],
      "estimated_nodes": [
        8,
        15
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    },
    {
      "challenge_id": "WF420",
      "level": 4,
      "pattern": "cyclic",
      "domain": "content_analysis",
      "title": "Content Moderation System with Feedback Loop",
      "description": "Create a content analysis pipeline that processes text documents, performs sentiment analysis, and generates insights. Implement enterprise-grade analysis techniques. Include iterative refinement based on quality feedback.",
      "requirements": [
        "Use appropriate Kailash SDK nodes for the task",
        "Implement proper error handling for external dependencies",
        "Include logging and monitoring capabilities",
        "Ensure data validation at input and output stages",
        "Support configurable parameters for different environments",
        "Implement retry logic for unreliable operations",
        "Include performance optimization for large data volumes",
        "Implement circuit breaker pattern for external services",
        "Support parallel processing where applicable",
        "Implement comprehensive audit logging",
        "Support dynamic workflow reconfiguration",
        "Include metrics collection and reporting",
        "Ensure enterprise-grade reliability patterns",
        "Implement convergence criteria to avoid infinite loops"
      ],
      "constraints": [
        "Use LocalRuntime for execution",
        "Maximum 20 nodes in the workflow",
        "Demonstrate enterprise architecture patterns",
        "Include both cycles and parallel processing"
      ],
      "success_criteria": {
        "functional": [
          "Workflow executes without errors",
          "All nodes properly connected",
          "Expected output format produced",
          "Parallel processing utilized where beneficial",
          "Enterprise patterns demonstrated",
          "Comprehensive error recovery"
        ],
        "code_quality": [
          "Proper import statements",
          "Correct parameter declarations",
          "No deprecated patterns used",
          "Error handling implemented",
          "Appropriate node types selected",
          "Production-ready code quality",
          "Proper documentation and comments"
        ],
        "performance": [
          "Reasonable execution time",
          "Efficient resource usage",
          "Optimized for concurrent execution"
        ]
      },
      "planted_errors": [
        {
          "type": "no_error_handling",
          "description": "Missing error handling for external services",
          "detection_difficulty": "hard"
        },
        {
          "type": "import_order_issues",
          "description": "Imports not ordered according to PEP 8",
          "detection_difficulty": "easy"
        },
        {
          "type": "missing_imports",
          "description": "Required import statements missing",
          "detection_difficulty": "easy"
        },
        {
          "type": "wrong_connection_syntax",
          "description": "Using 2-parameter instead of 4-parameter connection syntax",
          "detection_difficulty": "easy"
        }
      ],
      "estimated_nodes": [
        3,
        6
      ],
      "metadata": {
        "created_for_testing": true,
        "bias_free": true,
        "difficulty_level": 4,
        "expected_duration_minutes": 30
      }
    }
  ]
}