# Kailash SDK API Reference - Base Nodes
# Modules: kailash.nodes.base, kailash.nodes.base_async, kailash.nodes.base_cycle_aware
# Version: 0.1.4
# Last Updated: 2025-01-06

base_classes:
  node:
    class: kailash.nodes.base.Node
    description: "Base class for all workflow nodes"
    import: "from kailash.nodes.base import Node"
    abstract: true
    config:
      node_id: "str - Unique identifier for the node (auto-generated if not provided)"
      name: "str - Human-readable name for the node (optional)"
      description: "str - Description of the node's purpose (optional)"
      tags: "List[str] - Tags for categorizing the node (optional)"
      timeout: "float - Maximum execution time in seconds (optional)"
      retry_count: "int - Number of retry attempts on failure (default: 0)"
      retry_delay: "float - Delay between retries in seconds (default: 1.0)"
    methods:
      __init__:
        signature: "__init__(self, **config)"
        description: "Initialize the node with configuration"
        params:
          config: "Configuration parameters as keyword arguments"
        example: |
          class MyNode(Node):
              def __init__(self, **config):
                  # Set attributes BEFORE calling super().__init__()
                  self.custom_param = config.get('custom_param', 'default')
                  super().__init__(**config)

      get_parameters:
        signature: "get_parameters(self) -> Dict[str, NodeParameter]"
        description: "Return dictionary of node parameters for UI/validation"
        returns: "Dictionary mapping parameter names to NodeParameter objects"
        example: |
          def get_parameters(self):
              return {
                  'input_file': NodeParameter(
                      name='input_file',
                      type='string',
                      required=True,
                      description='Path to input file'
                  ),
                  'threshold': NodeParameter(
                      name='threshold',
                      type='float',
                      required=False,
                      default=0.5,
                      description='Processing threshold'
                  )
              }

      validate_config:
        signature: "validate_config(self, config: Dict[str, Any]) -> bool"
        description: "Validate node configuration before execution"
        params:
          config: "Configuration dictionary to validate"
        returns: "True if valid, raises exception if invalid"
        example: |
          def validate_config(self, config):
              if 'required_param' not in config:
                  raise ValueError("required_param is missing")
              if config.get('threshold', 0) < 0:
                  raise ValueError("threshold must be non-negative")
              return True

      execute:
        signature: "execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]"
        description: "Execute the node's main functionality"
        params:
          inputs: "Input data dictionary"
        returns: "Output data dictionary"
        abstract: true
        example: |
          def execute(self, inputs):
              # Process the inputs
              data = inputs.get('data', [])
              processed = [x * 2 for x in data]

              # Return outputs
              return {
                  'result': processed,
                  'count': len(processed)
              }

      get_input_schema:
        signature: "get_input_schema(self) -> Dict[str, Any]"
        description: "Get JSON schema for input validation"
        returns: "JSON schema dictionary"
        example: |
          def get_input_schema(self):
              return {
                  'type': 'object',
                  'properties': {
                      'data': {
                          'type': 'array',
                          'items': {'type': 'number'},
                          'description': 'Input data array'
                      }
                  },
                  'required': ['data']
              }

      get_output_schema:
        signature: "get_output_schema(self) -> Dict[str, Any]"
        description: "Get JSON schema for output validation"
        returns: "JSON schema dictionary"
        example: |
          def get_output_schema(self):
              return {
                  'type': 'object',
                  'properties': {
                      'result': {
                          'type': 'array',
                          'items': {'type': 'number'}
                      },
                      'count': {'type': 'integer'}
                  },
                  'required': ['result', 'count']
              }

  async_node:
    class: kailash.nodes.base_async.AsyncNode
    description: "Base class for asynchronous workflow nodes"
    import: "from kailash.nodes.base_async import AsyncNode"
    inherits: "Node"
    methods:
      execute_async:
        signature: "async execute_async(self, inputs: Dict[str, Any]) -> Dict[str, Any]"
        description: "Asynchronous execution method"
        params:
          inputs: "Input data dictionary"
        returns: "Output data dictionary"
        abstract: true
        example: |
          async def execute_async(self, inputs):
              # Async processing
              async with aiohttp.ClientSession() as session:
                  async with session.get(inputs['url']) as response:
                      data = await response.json()

              return {'data': data, 'status': 'success'}

      execute:
        signature: "execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]"
        description: "Synchronous wrapper for async execution"
        params:
          inputs: "Input data dictionary"
        returns: "Output data dictionary"
        example: |
          # Automatically provided - runs execute_async in event loop
          def execute(self, inputs):
              return asyncio.run(self.execute_async(inputs))

  cycle_aware_node:
    class: kailash.nodes.base_cycle_aware.CycleAwareNode
    description: "Base class for nodes that can participate in cyclic workflows"
    import: "from kailash.nodes.base_cycle_aware import CycleAwareNode"
    inherits: "Node"
    config:
      cycle_id: "str - Identifier for the cycle this node participates in"
      max_iterations: "int - Maximum number of cycle iterations (default: 10)"
      convergence_threshold: "float - Threshold for convergence detection (optional)"
      state_persistence: "bool - Whether to persist state between cycles (default: True)"
    methods:
      get_cycle_state:
        signature: "get_cycle_state(self, cycle_id: str) -> Dict[str, Any]"
        description: "Get the current state for a specific cycle"
        params:
          cycle_id: "Cycle identifier"
        returns: "State dictionary"
        example: |
          def execute(self, inputs):
              cycle_id = self.config.get('cycle_id')
              if cycle_id:
                  state = self.get_cycle_state(cycle_id)
                  iteration = state.get('iteration', 0)

              # Process with cycle awareness
              result = self.process_with_state(inputs, state)
              return result

      set_cycle_state:
        signature: "set_cycle_state(self, cycle_id: str, state: Dict[str, Any]) -> None"
        description: "Update the state for a specific cycle"
        params:
          cycle_id: "Cycle identifier"
          state: "State dictionary to store"
        example: |
          def execute(self, inputs):
              # Process inputs
              result = self.process_inputs(inputs)

              # Update cycle state
              cycle_id = self.config.get('cycle_id')
              if cycle_id:
                  new_state = {
                      'iteration': result.get('iteration', 0) + 1,
                      'quality_score': result.get('quality', 0),
                      'last_result': result
                  }
                  self.set_cycle_state(cycle_id, new_state)

              return result

      check_convergence:
        signature: "check_convergence(self, cycle_id: str, current_result: Dict[str, Any]) -> bool"
        description: "Check if the cycle has converged"
        params:
          cycle_id: "Cycle identifier"
          current_result: "Current execution result"
        returns: "True if converged, False otherwise"
        example: |
          def check_convergence(self, cycle_id, current_result):
              state = self.get_cycle_state(cycle_id)
              previous_result = state.get('last_result')

              if not previous_result:
                  return False

              # Check for convergence based on result similarity
              current_score = current_result.get('quality_score', 0)
              previous_score = previous_result.get('quality_score', 0)

              threshold = self.config.get('convergence_threshold', 0.01)
              return abs(current_score - previous_score) < threshold

      reset_cycle_state:
        signature: "reset_cycle_state(self, cycle_id: str) -> None"
        description: "Reset the state for a specific cycle"
        params:
          cycle_id: "Cycle identifier"
        example: |
          # Reset state when starting a new cycle run
          self.reset_cycle_state('data_processing_cycle')

node_registry:
  register_node:
    description: "Decorator to register custom nodes with the node registry"
    import: "from kailash.nodes import register_node"
    signature: "register_node(name: Optional[str] = None, category: str = 'custom', version: str = '1.0.0')"
    params:
      name: "Custom name for the node (defaults to class name)"
      category: "Node category for organization"
      version: "Node version for compatibility tracking"
    example: |
      from kailash.nodes import register_node
      from kailash.nodes.base import Node

      @register_node(name='DataProcessor', category='data', version='1.0.0')
      class DataProcessorNode(Node):
          def __init__(self, **config):
              self.processing_mode = config.get('processing_mode', 'simple')
              self.batch_size = config.get('batch_size', 100)
              super().__init__(**config)

          def get_parameters(self):
              return {
                  'processing_mode': NodeParameter(
                      name='processing_mode',
                      type='string',
                      required=False,
                      default='simple',
                      options=['simple', 'advanced', 'batch'],
                      description='Processing mode to use'
                  ),
                  'batch_size': NodeParameter(
                      name='batch_size',
                      type='integer',
                      required=False,
                      default=100,
                      min_value=1,
                      max_value=1000,
                      description='Batch size for processing'
                  )
              }

          def validate_config(self, config):
              mode = config.get('processing_mode', 'simple')
              if mode not in ['simple', 'advanced', 'batch']:
                  raise ValueError(f"Invalid processing_mode: {mode}")

              batch_size = config.get('batch_size', 100)
              if not isinstance(batch_size, int) or batch_size < 1:
                  raise ValueError("batch_size must be a positive integer")

              return True

          def execute(self, inputs):
              data = inputs.get('data', [])

              if self.processing_mode == 'batch':
                  # Process in batches
                  results = []
                  for i in range(0, len(data), self.batch_size):
                      batch = data[i:i + self.batch_size]
                      batch_result = self.process_batch(batch)
                      results.extend(batch_result)
                  return {'result': results}
              else:
                  # Process all at once
                  result = self.process_data(data)
                  return {'result': result}

          def process_batch(self, batch):
              # Custom batch processing logic
              return [item * 2 for item in batch]

          def process_data(self, data):
              # Custom data processing logic
              if self.processing_mode == 'advanced':
                  return [item ** 2 for item in data]
              else:
                  return [item * 2 for item in data]

  get_registered_nodes:
    description: "Get all registered nodes"
    import: "from kailash.nodes import get_registered_nodes"
    signature: "get_registered_nodes(category: Optional[str] = None) -> Dict[str, Type[Node]]"
    params:
      category: "Filter by category (optional)"
    returns: "Dictionary mapping node names to node classes"
    example: |
      from kailash.nodes import get_registered_nodes

      # Get all nodes
      all_nodes = get_registered_nodes()
      print(f"Available nodes: {list(all_nodes.keys())}")

      # Get nodes by category
      data_nodes = get_registered_nodes(category='data')
      ai_nodes = get_registered_nodes(category='ai')

  create_node:
    description: "Create a node instance from registry"
    import: "from kailash.nodes import create_node"
    signature: "create_node(node_name: str, **config) -> Node"
    params:
      node_name: "Name of the registered node"
      config: "Configuration parameters"
    returns: "Node instance"
    example: |
      from kailash.nodes import create_node

      # Create node from registry
      processor = create_node('DataProcessor',
                            processing_mode='advanced',
                            batch_size=50)

      # Use in workflow
      workflow.add_node('processor', processor)

node_parameter:
  class: kailash.nodes.base.NodeParameter
  description: "Parameter definition for node configuration"
  import: "from kailash.nodes.base import NodeParameter"
  config:
    name: "str - Parameter name"
    type: "str - Parameter type ('string', 'integer', 'float', 'boolean', 'array', 'object')"
    required: "bool - Whether parameter is required (default: False)"
    default: "Any - Default value (optional)"
    description: "str - Parameter description (optional)"
    options: "List[Any] - Valid options for the parameter (optional)"
    min_value: "Union[int, float] - Minimum value for numeric types (optional)"
    max_value: "Union[int, float] - Maximum value for numeric types (optional)"
    pattern: "str - Regex pattern for string validation (optional)"
    format: "str - Format specification (e.g., 'email', 'url', 'date') (optional)"
  methods:
    validate:
      signature: "validate(self, value: Any) -> bool"
      description: "Validate a value against this parameter definition"
      params:
        value: "Value to validate"
      returns: "True if valid, raises exception if invalid"
      example: |
        param = NodeParameter(
            name='threshold',
            type='float',
            required=True,
            min_value=0.0,
            max_value=1.0
        )

        param.validate(0.5)  # Returns True
        param.validate(1.5)  # Raises ValueError

  example: |
    from kailash.nodes.base import NodeParameter

    # String parameter with options
    mode_param = NodeParameter(
        name='mode',
        type='string',
        required=True,
        options=['fast', 'accurate', 'balanced'],
        description='Processing mode'
    )

    # Numeric parameter with range
    threshold_param = NodeParameter(
        name='threshold',
        type='float',
        required=False,
        default=0.5,
        min_value=0.0,
        max_value=1.0,
        description='Decision threshold'
    )

    # Array parameter
    tags_param = NodeParameter(
        name='tags',
        type='array',
        required=False,
        default=[],
        description='Processing tags'
    )

    # Object parameter
    config_param = NodeParameter(
        name='advanced_config',
        type='object',
        required=False,
        default={},
        description='Advanced configuration options'
    )

node_development_patterns:
  description: "Common patterns and best practices for node development"
  patterns:
    basic_node:
      description: "Simple node with basic functionality"
      example: |
        from kailash.nodes.base import Node, NodeParameter
        from kailash.nodes import register_node

        @register_node('SimpleProcessor')
        class SimpleProcessorNode(Node):
            def __init__(self, **config):
                # Set attributes BEFORE super().__init__()
                self.multiplier = config.get('multiplier', 2)
                super().__init__(**config)

            def get_parameters(self):
                return {
                    'multiplier': NodeParameter(
                        name='multiplier',
                        type='integer',
                        required=False,
                        default=2,
                        description='Multiplication factor'
                    )
                }

            def execute(self, inputs):
                data = inputs.get('data', [])
                result = [x * self.multiplier for x in data]
                return {'result': result}

    async_node:
      description: "Asynchronous node for I/O operations"
      example: |
        import asyncio
        import aiohttp
        from kailash.nodes.base_async import AsyncNode
        from kailash.nodes import register_node

        @register_node('AsyncAPIClient')
        class AsyncAPIClientNode(AsyncNode):
            def __init__(self, **config):
                self.api_url = config.get('api_url', '')
                self.timeout = config.get('timeout', 30)
                super().__init__(**config)

            async def execute_async(self, inputs):
                endpoint = inputs.get('endpoint', '')
                url = f"{self.api_url}/{endpoint}"

                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=self.timeout) as response:
                        data = await response.json()
                        return {
                            'data': data,
                            'status_code': response.status,
                            'url': url
                        }

    cycle_aware_node:
      description: "Node that maintains state across cycle iterations"
      example: |
        from kailash.nodes.base_cycle_aware import CycleAwareNode
        from kailash.nodes import register_node

        @register_node('IterativeOptimizer')
        class IterativeOptimizerNode(CycleAwareNode):
            def __init__(self, **config):
                self.learning_rate = config.get('learning_rate', 0.1)
                self.target_quality = config.get('target_quality', 0.9)
                super().__init__(**config)

            def execute(self, inputs):
                cycle_id = self.config.get('cycle_id')
                state = self.get_cycle_state(cycle_id) if cycle_id else {}

                # Get current parameters or initialize
                current_params = state.get('parameters', inputs.get('initial_params', []))
                iteration = state.get('iteration', 0)

                # Optimize parameters
                new_params = self.optimize_step(current_params, inputs.get('feedback', 0))
                quality = self.evaluate_quality(new_params, inputs.get('target', 0))

                # Update state
                if cycle_id:
                    new_state = {
                        'parameters': new_params,
                        'iteration': iteration + 1,
                        'quality': quality,
                        'converged': quality >= self.target_quality
                    }
                    self.set_cycle_state(cycle_id, new_state)

                return {
                    'parameters': new_params,
                    'quality': quality,
                    'iteration': iteration + 1,
                    'converged': quality >= self.target_quality
                }

            def optimize_step(self, params, feedback):
                # Simple gradient descent step
                return [p + self.learning_rate * feedback for p in params]

            def evaluate_quality(self, params, target):
                # Simple quality metric
                return 1.0 / (1.0 + abs(sum(params) - target))

    error_handling:
      description: "Node with comprehensive error handling"
      example: |
        import logging
        from kailash.nodes.base import Node
        from kailash.nodes import register_node

        @register_node('RobustProcessor')
        class RobustProcessorNode(Node):
            def __init__(self, **config):
                self.fail_fast = config.get('fail_fast', False)
                self.default_value = config.get('default_value', None)
                super().__init__(**config)

            def execute(self, inputs):
                try:
                    return self._safe_execute(inputs)
                except Exception as e:
                    logging.error(f"Node {self.node_id} failed: {str(e)}")

                    if self.fail_fast:
                        raise

                    # Return default or error result
                    return {
                        'result': self.default_value,
                        'error': str(e),
                        'success': False
                    }

            def _safe_execute(self, inputs):
                # Validate inputs
                if 'data' not in inputs:
                    raise ValueError("Missing required input: data")

                data = inputs['data']
                if not isinstance(data, list):
                    raise TypeError("Input data must be a list")

                # Process data with error handling
                results = []
                errors = []

                for i, item in enumerate(data):
                    try:
                        result = self.process_item(item)
                        results.append(result)
                    except Exception as e:
                        errors.append(f"Item {i}: {str(e)}")
                        if not self.fail_fast:
                            results.append(self.default_value)
                        else:
                            raise

                return {
                    'result': results,
                    'errors': errors,
                    'success': len(errors) == 0
                }

            def process_item(self, item):
                # Custom processing logic that might fail
                if item is None:
                    raise ValueError("Cannot process None item")
                return item * 2

best_practices:
  description: "Best practices for node development"
  guidelines: |
    1. **Initialization Order**: Always set custom attributes BEFORE calling super().__init__()

    2. **Parameter Definition**: Use get_parameters() to define all configurable parameters

    3. **Validation**: Implement validate_config() for configuration validation

    4. **Error Handling**: Use try-catch blocks and provide meaningful error messages

    5. **State Management**: For cycle-aware nodes, always check for cycle_id before accessing state

    6. **Output Format**: Return dictionaries with descriptive keys for outputs

    7. **Documentation**: Include docstrings and parameter descriptions

    8. **Testing**: Write unit tests for all node functionality

    9. **Naming**: Use descriptive names ending with 'Node'

    10. **Resource Cleanup**: Implement proper cleanup in async nodes

  common_mistakes: |
    - Calling super().__init__() before setting attributes
    - Not implementing get_parameters() for UI integration
    - Missing input validation in execute()
    - Not handling edge cases (empty inputs, None values)
    - Forgetting to register custom nodes
    - Not providing default values for optional parameters
    - Mixing sync and async code without proper handling
    - Not cleaning up resources in async nodes
