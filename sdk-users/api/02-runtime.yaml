# Kailash SDK API Reference - Runtime
# Module: kailash.runtime
# Version: 0.1.4
# Last Updated: 2025-01-06

runtime:
  local_runtime:
    class: kailash.LocalRuntime
    description: "Execute workflows locally with full async support and enterprise features"
    import: "from kailash import LocalRuntime"
    config:
      max_workers: "int - Maximum number of worker threads (default: 4)"
      timeout: "float - Default timeout for node execution in seconds (default: 300)"
      enable_metrics: "bool - Enable performance metrics collection (default: True)"
      log_level: "str - Logging level ('DEBUG', 'INFO', 'WARNING', 'ERROR') (default: 'INFO')"
      execution_mode: "str - Execution mode ('sequential', 'parallel', 'auto') (default: 'auto')"
      cache_enabled: "bool - Enable execution result caching (default: True)"
      resource_limits: "dict - Resource limits for execution"
    methods:
      execute:
        signature: "execute(workflow: Workflow, inputs: Optional[Dict[str, Any]] = None, task_manager: Optional[TaskManager] = None, execution_context: Optional[Dict[str, Any]] = None) -> Tuple[Dict[str, Any], str]"
        description: "Execute a workflow and return results with run ID"
        params:
          workflow: "Workflow instance to execute"
          inputs: "Initial inputs to the workflow (optional)"
          task_manager: "Task manager for tracking execution (optional)"
          execution_context: "Additional context for execution (optional)"
        returns: "Tuple of (results, run_id)"
        example: |
          runtime = LocalRuntime(max_workers=8, timeout=600)
          results, run_id = runtime.execute(workflow, parameters={'data': [1, 2, 3]})
          print(f"Execution {run_id} completed with results: {results}")

      execute_async:
        signature: "async execute_async(workflow: Workflow, parameters: Optional[Dict[str, Any]] = None, task_manager: Optional[TaskManager] = None) -> Tuple[Dict[str, Any], str]"
        description: "Asynchronously execute a workflow"
        params:
          workflow: "Workflow instance to execute"
          inputs: "Initial inputs to the workflow (optional)"
          task_manager: "Task manager for tracking execution (optional)"
        returns: "Tuple of (results, run_id)"
        example: |
          import asyncio
          runtime = LocalRuntime()
          results, run_id = await runtime.execute_async(workflow)

      validate_workflow:
        signature: "validate_workflow(workflow: Workflow) -> bool"
        description: "Validate workflow before execution"
        params:
          workflow: "Workflow to validate"
        returns: "True if valid, raises exception if invalid"
        example: |
          runtime = LocalRuntime()
          runtime.validate_workflow(workflow)  # Raises if invalid

      get_execution_stats:
        signature: "get_execution_stats(run_id: str) -> Dict[str, Any]"
        description: "Get execution statistics for a completed run"
        params:
          run_id: "Run ID from execute() call"
        returns: "Dictionary with execution metrics"
        example: |
          stats = runtime.get_execution_stats(run_id)
          print(f"Execution time: {stats['execution_time']}s")

      set_resource_limits:
        signature: "set_resource_limits(memory_mb: int, cpu_percent: float) -> None"
        description: "Set resource limits for workflow execution"
        params:
          memory_mb: "Maximum memory usage in MB"
          cpu_percent: "Maximum CPU usage percentage"
        example: |
          runtime.set_resource_limits(memory_mb=1024, cpu_percent=80.0)

    example: |
      # Basic usage
      runtime = LocalRuntime()
      results, run_id = runtime.execute(workflow)

      # Advanced configuration
      runtime = LocalRuntime(
          max_workers=8,
          timeout=600,
          enable_metrics=True,
          execution_mode='parallel',
          resource_limits={'memory_mb': 2048, 'cpu_percent': 90}
      )

      # With custom task manager
      from kailash.tracking import TaskTracker
      tracker = TaskTracker()
      results, run_id = runtime.execute(workflow, task_manager=tracker)

      # Async execution
      async def run_workflow():
          results, run_id = await runtime.execute_async(workflow)
          return results

  docker_runtime:
    class: kailash.runtime.DockerRuntime
    description: "Execute workflows in Docker containers for isolation and scalability"
    import: "from kailash.runtime import DockerRuntime"
    config:
      base_image: "str - Docker base image (default: 'python:3.9-slim')"
      container_name: "str - Container name prefix (default: 'kailash-workflow')"
      network_mode: "str - Docker network mode (default: 'bridge')"
      volumes: "List[str] - Volume mounts for the container"
      environment: "Dict[str, str] - Environment variables"
      memory_limit: "str - Memory limit (e.g., '1g', '512m')"
      cpu_limit: "float - CPU limit (default: 1.0)"
      remove_container: "bool - Remove container after execution (default: True)"
      timeout: "float - Container execution timeout in seconds (default: 3600)"
    methods:
      execute:
        signature: "execute(workflow: Workflow, inputs: Optional[Dict[str, Any]] = None, task_manager: Optional[TaskManager] = None) -> Tuple[Dict[str, Any], str]"
        description: "Execute workflow in Docker container"
        params:
          workflow: "Workflow instance to execute"
          inputs: "Initial inputs to the workflow (optional)"
          task_manager: "Task manager for tracking execution (optional)"
        returns: "Tuple of (results, run_id)"
        example: |
          runtime = DockerRuntime(base_image='python:3.9-slim')
          results, run_id = runtime.execute(workflow, parameters={'data': data})

      build_image:
        signature: "build_image(dockerfile_path: str, tag: str, context_path: str = '.') -> str"
        description: "Build custom Docker image for workflow execution"
        params:
          dockerfile_path: "Path to Dockerfile"
          tag: "Image tag"
          context_path: "Build context path (default: '.')"
        returns: "Built image ID"
        example: |
          image_id = runtime.build_image('./Dockerfile', 'my-workflow:latest')

      list_containers:
        signature: "list_containers(filter_labels: Optional[Dict[str, str]] = None) -> List[Dict[str, Any]]"
        description: "List running workflow containers"
        params:
          filter_labels: "Labels to filter containers (optional)"
        returns: "List of container information"
        example: |
          containers = runtime.list_containers({'workflow': 'data-pipeline'})

      cleanup:
        signature: "cleanup(older_than_hours: int = 24) -> int"
        description: "Clean up old workflow containers"
        params:
          older_than_hours: "Remove containers older than specified hours"
        returns: "Number of containers removed"
        example: |
          removed_count = runtime.cleanup(older_than_hours=12)

    example: |
      # Basic Docker execution
      runtime = DockerRuntime(base_image='python:3.9')
      results, run_id = runtime.execute(workflow)

      # Advanced configuration
      runtime = DockerRuntime(
          base_image='python:3.9-slim',
          memory_limit='2g',
          cpu_limit=2.0,
          volumes=['/data:/app/data:ro'],
          environment={'PYTHONPATH': '/app', 'LOG_LEVEL': 'DEBUG'},
          network_mode='host'
      )

      # Custom image build and execution
      image_id = runtime.build_image('./docker/Dockerfile', 'my-workflow:v1.0')
      runtime.base_image = 'my-workflow:v1.0'
      results, run_id = runtime.execute(workflow)

      # Container management
      containers = runtime.list_containers()
      cleaned = runtime.cleanup(older_than_hours=6)

  cluster_runtime:
    class: kailash.runtime.ClusterRuntime
    description: "Execute workflows on Kubernetes clusters for production scalability"
    import: "from kailash.runtime import ClusterRuntime"
    config:
      cluster_config: "str - Path to kubeconfig file or cluster configuration"
      namespace: "str - Kubernetes namespace (default: 'default')"
      image: "str - Container image for workflow execution"
      resource_requests: "dict - Resource requests (cpu, memory)"
      resource_limits: "dict - Resource limits (cpu, memory)"
      node_selector: "Dict[str, str] - Node selector for pod placement"
      tolerations: "List[dict] - Pod tolerations"
      affinity: "dict - Pod affinity rules"
      service_account: "str - Service account name"
      image_pull_policy: "str - Image pull policy ('Always', 'IfNotPresent', 'Never')"
    methods:
      execute:
        signature: "execute(workflow: Workflow, inputs: Optional[Dict[str, Any]] = None, task_manager: Optional[TaskManager] = None) -> Tuple[Dict[str, Any], str]"
        description: "Execute workflow on Kubernetes cluster"
        params:
          workflow: "Workflow instance to execute"
          inputs: "Initial inputs to the workflow (optional)"
          task_manager: "Task manager for tracking execution (optional)"
        returns: "Tuple of (results, run_id)"
        example: |
          runtime = ClusterRuntime(cluster_config='~/.kube/config')
          results, run_id = runtime.execute(workflow)

      scale_cluster:
        signature: "scale_cluster(replicas: int, workflow_name: str) -> bool"
        description: "Scale workflow deployment on cluster"
        params:
          replicas: "Number of replicas"
          workflow_name: "Name of workflow deployment"
        returns: "True if scaling successful"
        example: |
          success = runtime.scale_cluster(replicas=5, workflow_name='data-pipeline')

      get_cluster_status:
        signature: "get_cluster_status() -> Dict[str, Any]"
        description: "Get cluster resource status"
        returns: "Cluster status information"
        example: |
          status = runtime.get_cluster_status()
          print(f"Available nodes: {status['nodes']['ready']}")

    example: |
      # Basic cluster execution
      runtime = ClusterRuntime(
          cluster_config='~/.kube/config',
          namespace='workflows',
          image='my-workflow:latest'
      )
      results, run_id = runtime.execute(workflow)

      # Production configuration
      runtime = ClusterRuntime(
          cluster_config='~/.kube/config',
          namespace='production',
          image='workflow-runner:v2.1.0',
          resource_requests={'cpu': '500m', 'memory': '1Gi'},
          resource_limits={'cpu': '2', 'memory': '4Gi'},
          node_selector={'workload': 'compute-intensive'},
          service_account='workflow-runner'
      )

      # Scale and monitor
      runtime.scale_cluster(replicas=10, workflow_name='batch-processor')
      status = runtime.get_cluster_status()

runtime_factory:
  class: kailash.runtime.RuntimeFactory
  description: "Factory for creating runtime instances based on configuration"
  import: "from kailash.runtime import RuntimeFactory"
  methods:
    create_runtime:
      signature: "create_runtime(runtime_type: str, config: Dict[str, Any]) -> BaseRuntime"
      description: "Create runtime instance from configuration"
      params:
        runtime_type: "Type of runtime ('local', 'docker', 'cluster')"
        config: "Runtime configuration dictionary"
      returns: "Runtime instance"
      example: |
        factory = RuntimeFactory()
        runtime = factory.create_runtime('docker', {
            'base_image': 'python:3.9',
            'memory_limit': '2g'
        })

    get_available_runtimes:
      signature: "get_available_runtimes() -> List[str]"
      description: "Get list of available runtime types"
      returns: "List of runtime type names"
      example: |
        factory = RuntimeFactory()
        runtimes = factory.get_available_runtimes()
        # ['local', 'docker', 'cluster']

  example: |
    from kailash.runtime import RuntimeFactory

    factory = RuntimeFactory()

    # Create different runtime types
    local_runtime = factory.create_runtime('local', {'max_workers': 8})
    docker_runtime = factory.create_runtime('docker', {
        'base_image': 'python:3.9',
        'memory_limit': '1g'
    })
    cluster_runtime = factory.create_runtime('cluster', {
        'cluster_config': '~/.kube/config',
        'namespace': 'workflows'
    })

performance_tuning:
  description: "Runtime performance optimization guidelines"
  best_practices: |
    # LocalRuntime Optimization
    - Use parallel execution mode for independent nodes
    - Set appropriate max_workers based on CPU cores
    - Enable caching for repeated operations
    - Monitor memory usage with resource limits

    # DockerRuntime Optimization
    - Use slim base images to reduce startup time
    - Pre-build custom images with dependencies
    - Mount volumes for large data instead of copying
    - Set appropriate memory and CPU limits

    # ClusterRuntime Optimization
    - Use horizontal pod autoscaling for variable loads
    - Configure resource requests and limits appropriately
    - Use node affinity for workload placement
    - Implement proper health checks and monitoring

  examples: |
    # Performance monitoring
    runtime = LocalRuntime(enable_metrics=True)
    results, run_id = runtime.execute(workflow)
    stats = runtime.get_execution_stats(run_id)

    print(f"Execution time: {stats['execution_time']}s")
    print(f"Memory peak: {stats['memory_peak_mb']}MB")
    print(f"CPU utilization: {stats['cpu_utilization']}%")

    # Resource optimization
    if stats['memory_peak_mb'] > 1000:
        runtime.set_resource_limits(memory_mb=2048, cpu_percent=80)

    # Cluster scaling based on load
    cluster_runtime = ClusterRuntime()
    status = cluster_runtime.get_cluster_status()
    if status['cpu_utilization'] > 80:
        cluster_runtime.scale_cluster(replicas=status['replicas'] * 2)
